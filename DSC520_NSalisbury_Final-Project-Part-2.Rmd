---
title: 'Final Project: Oscar Predictions - Part 2'
author: "Nicholas Salisbury"
date: "2/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Libraries
```{r load_libs}
library(readr)
library(ggplot2)
library(magrittr)
library(tidyr)
library(pastecs)
library(dplyr)
```

## Additional Data Cleaning
As I got into my project a bit more and away from data cleaning, I realized there was more data cleaning work to do. Part of this hearkens back to to DSC500 (I think). I initially thought that more data is better. But that isn't always the case. 

After reviewing some of my data, I realized I needed to narrow my focus.

```{r load_format_data}
# Load data
oscar_preds <- read_csv("oscar-prediction-dataset-1000v.csv")

# Split comma separate genre column into multiple genre columns.
oscar_preds <- oscar_preds %>% separate(genres, c("genre_1", "genre_2", "genre_3"), ",", extra = "drop", fill = "right")

```

Even though there was an Oscar winner in the "Film-noir" genre, there were just too many genres. And most of them had few if any Oscar winners. Now removing these genre's means my analysis will not be able to accurately predict movies in those genre's, but it will hopefully still be able to predict the majority of films.

```{r bad_genres, echo=FALSE}
# This will list alllllll of our genres and how many movies are labeled as that genre
ggplot(data=oscar_preds, aes(x=oscar_preds$genre_1)) +
  geom_bar()
```

If you manage to actually look at the graph above, you will see there are a couple of suspect genres, and just some genres that are probably insignificant.
```{r clean_up_genres}
# note some peculiar genres from graph above, review data
subset(oscar_preds, genre_1 == 'NULL' | genre_1 == 'Adult', select = c(primary_title))

## Remove 2 "adult" records. Convert 2 null to documentary based on additional research (The Cleaners and Jane Fonda in Five Acts)
oscar_preds$genre_1[oscar_preds$genre_1 == "NULL"] <- 'Documentary'
oscar_preds <- subset(oscar_preds, genre_1 != "Adult")

# Oscars seem to congregate around certain genre's. I think we should remove non-relevant genres
subset(subset(oscar_preds, have_win == 1) %>% 
         group_by(genre_1) %>%
         tally(), n >= 50)

# Remove everything not in specified genres
oscar_preds <- subset(oscar_preds, genre_1 %in% cbind("Action","Adventure","Biography","Comedy","Crime","Drama"))

# Re-plot genres again
ggplot(data=oscar_preds, aes(x=oscar_preds$genre_1)) +
  geom_bar()
```

Another way to reduce my overwhelming data set was to focus only on feature films. These are films identified by the academy as greater than 40 minutes. So I removed anything less than that. I also removed anything that was identified as a "short" in any of the genre fields. Other film institutions have different runtime requirements, so if a film was labeled as a short, I wanted to remove it.
```{r no_shorts}
# a few runtimes were expressed as chars, resulting in the column be a char. convert to number
oscar_preds <- transform(oscar_preds, runtime_minutes = as.numeric(runtime_minutes))

# Throw away NAs and "shorts"
oscar_preds <- subset(oscar_preds, !is.na(oscar_preds$runtime_minutes) & oscar_preds$runtime_minutes > 40 & genre_1 != "Short"
                      & genre_2 != "Short" & genre_3 != "Short" )

# Re-plot genres again
ggplot(data=oscar_preds, aes(x=oscar_preds$genre_1)) +
  geom_bar()
```

# Discuss how you plan to uncover new information in the data that is not self-evident
I wanted to do some basic analyizing to see if I could use number of votes or average rating so I looked at various different items, such as the distribution of average_rating and number_votes. I used histograms and the stat.desc function. I have some pretty significant skew in both data points.

```{r some_basics}
# Check on the distribution of our average rating
ggplot(data=oscar_preds, aes(x=oscar_preds$average_rating)) +
  geom_histogram(binwidth = 0.25)

stat.desc(oscar_preds[sample(nrow(oscar_preds), 5000), "average_rating"], basic = FALSE, norm = TRUE)

# Check our distribution of number of votes... hmm something is askew here.
ggplot(data=oscar_preds, aes(x=oscar_preds$number_votes)) +
  geom_histogram(binwidth = 100000)

# Whoa our skew and kurtosis is bad. As bad as your halitosis.
stat.desc(oscar_preds[sample(nrow(oscar_preds), 5000), "number_votes"], basic = FALSE, norm = TRUE)

# Get an idea of counts
# How many oscar winners? 589
sum(oscar_preds$have_win == 1)

# How many films have less than 100,000 votes? 12960
sum(oscar_preds$number_votes < 100000)

# How many films have more than or equal to 100,000 votes? 1182
sum(oscar_preds$number_votes >= 100000)

# What is minimum (1001 votes) & mean (25021.28) number of votes for an oscar winner, mostly for curiosity?
min(subset(oscar_preds, have_win = 1, select=c(number_votes)))
subset(oscar_preds, have_win = 1, select=c(number_votes)) %>% lapply(mean)
```

## What are different ways you could look at this data to answer the questions you want to answer?

Trying to figure this out. Not sure that there is any from the current data. When I cleaned/created my dataset, I limited it to true/false values for my expected predictors. I did end up adding runtime and splitting my comma-separated genre list. I've poked and prodded the data a few different ways, but not sure how I am going use the variables besides the "prior" variables. An example of some of my poking around:

```{r genre_poking}
# Create new dataframe for just oscar winners
oscar_winners <- subset(oscar_preds, have_win == 1)

# Check our genre wins... shows that most genres are even. Compare this to total movies in genre
# And you see that action & comedy have a lot more movies! Maybe genre and winning is correlated
ggplot(data=oscar_winners, aes(x=oscar_winners$genre_1)) +
  geom_bar()

oscar_preds$genre.factor <- as.numeric(factor(oscar_preds$genre_1))
oscar_winners$genre.factor <- as.numeric(factor(oscar_winners$genre_1))

cor(oscar_preds$genre.factor,oscar_preds$have_win)^2
cor(oscar_winners$have_win,oscar_winners$genre.factor)
```
	
## Do you plan to slice and dice the data in different ways, create new variables, or join separate data frames to create new summary information? Explain.
I've displayed various ways already, by slicing the genre column into 3 columns. Adding a factor for the genre, subsetting out movies by runtime.

Also, one thing I skipped over so far was the Golden Globes data set. Mostly due to time constraints. I'm wondering if going back and adding this data would improve my modeling capabilities.

I'm still looking for additional ways to improve my data set!

## How could you summarize your data to answer key questions?
I did a basic correlation of my main predictor variables.

```{r cor_predict}
cor(oscar_preds[,c("have_win","prior_director_win","prior_actor_win","prior_writer_win","prior_other_win")])
```

## What types of plots and tables will help you to illustrate the findings to your questions? Ensure that all graph plots have axis titles, legend if necessary, scales are appropriate, appropriate geoms used, etc.).

I have a few bar and histogram plots. I don't think scatter plots really fit my data set.

## What do you not know how to do right now that you need to learn to answer your questions?
I need to revisit model generation. And what all of the different statistics mean (t, f, etc). I think this will be the biggest indicator of whether this data set can do anything. And I want to make sure I have a very good understand of the details generated by a model before I express thoughts based off those details.

## Do you plan on incorporating any machine learning techniques to answer your research questions? Explain.

Not at this time. I believe this data fits mostly to logistical regression model. And we don't need to incorporate any nearest neighbor algorithms. Though, I will look at subsetting data to build a training set to see how well the model can predict (if it can). So I guess that may include some machine learning?