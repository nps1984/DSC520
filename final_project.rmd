---
title: 'Final Project: Oscar Predictions'
author: "Nicholas Salisbury"
date: "2/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Data Importing and Cleaning Steps
This was a test of endurance. I came to realize that the data I chose to use was going to be a major obstacle. There were two main reasons for the challenge:
1. Most of the data is "community" entered. IMDb, especially early on relied on contributors for data (think Wikipedia). This means that the data is a bit inconsistent, which segue's into my next point...
2. Using IMDb for the majority of details and a totally separate, unrelated source proved problematic with inconsistencies.

What inconsistencies am I referring to? Mostly names. For example a movie in IMDb is titled as "Wallace & Gromit: The Curse of the Were-Rabbit" whereas in the Oscar dataset it was titled as "Wallace & Gromit in The Curse of the Were-Rabbit." Another issue regarding names of crewmembers is that IMDb utilizes different fields to describe the name. For example, Aaron Sorkin is a "writer" (category) and he wrote the "screenplay" (job) for The Social Network. But in the Oscars data set, he is identified as "screenplay by Aaron Sorkin."

Other issues I encountered with the datasets:
Foreign language characters would sometime display properly. And sometimes they would be replaced by other symbols.
Malformed and inconsistent quoting were another issue. Malformed because I may have a record with the title like this, "Frankenstein based on the novel by Mary Shelley (note only the opening quote). Another issue was the inconsitency in quoting. When describing source material, sometimes it would be single-quoted, double-quoted, or not quoted. Or sometimes when giving details about a TV epside, there would be inconsistent quoting. Albeit, this was not a major factor for my target data. But it did play a factor in importing the data!

Some notable data manipulation & filtering I performed included:

* As mentioned above, the issue with quotation led me to remove quotes in most cases.

* Some notable movies in the Oscar dataset had the wrong year attributed to them (see my week 9 assignment in regards to this concern). This happens when a movie is technically released at the end of the year, for example December 25th 2019, but maybe in only a few select theaters. This would qualify it for the 2020 Oscar ceremony. But since the film's wide release wasn't until 2020, the year is noted as 2020. I updated as many as I could find in the Oscar dataset. These are noted in my database.

* Filters applied include:
	+ Removing films before 1927 as this was the first year films were award Oscars.
	+ Removing films with 1000 or fewer votes.
	+ Removing anything that was not identified as a movie or short. This would include video games, tv episodes, tv movies, etc
	+ Removing anything labeled as adult

# Overview of Clean Data Set	
## Load Libraries

At this point, I am only loading my data, so I only have one library to load.

```{r load_libs}
library(readr)
```

## Inspect Data Setup

I am loading a dataset that was produced via SQL from a postgreSQL database.

```{r load_inspect_data}
oscar_preds <- read_csv("oscar-prediction-dataset-1000v.csv")

head(oscar_preds)

str(oscar_preds)
```





## Data Set Discussion
To give a brief synopsis of my dataset:

* Primary Title: Title of the film
* Genre: Comma separated list of genres
* Start Year: Year film was released
* Have Win: Did the film (or any crew member) win an Oscar
* Average Rating: Average rating of all ratings by IMDb users
* Number Votes: Total number of votes cast for a title
* Prior Director Win: Did the director of this film win an Oscar previously
* Prior Actor Win: Did an actor/actress of this film win an Oscar previously
* Prior Writer Win: Did the writer of this film win an Oscar previously
* Prior Other Win: Did any crew member previously win an Oscar

## SQL
I struggled with making my data usable. And I fell back to what I'm comfortable with and that is SQL. Part of my struggle is that using an external database and SQL scripts obfuscates some of the process. So to try and bring some transparency to my process, below is the query I utilized to pull the dataset I will use for my model.

```{sql clean_data, eval=FALSE}
SELECT	DISTINCT
		MIO.PRIMARY_TITLE,
		MIO.GENRES,
		MIO.START_YEAR,
		MAX(MIO.WIN) OVER (PARTITION BY PRIMARY_TITLE) AS HAVE_WIN,
		MIO.AVERAGE_RATING,
		MIO.NUMBER_VOTES,
		MPI.TITLE_CONSTANT,
		MPI.PRIOR_DIRECTOR_WIN,
		MPI.PRIOR_ACTOR_WIN,
		MPI.PRIOR_WRITER_WIN,
		MPI.PRIOR_OTHER_WIN
FROM	(	/*	GETS RELEVENT MOVIES BASED ON TYPE, YEAR, VOTES
				JOINS TO OSCARS TABLE TO GET WINNERS
				RETURNS BASIC DETAILS FOR FILM
			*/
			SELECT	MI.TITLE_CONSTANT,
					MI.PRIMARY_TITLE,
					MI.START_YEAR,
					MI.RUNTIME_MINUTES,
					MI.GENRES,
					O.CATEGORY,
					O.NAME,
					CASE
						WHEN O.WIN IS NULL OR O.WIN = 'False'
						THEN 0
						ELSE 1
					END AS WIN,
					MI.AVERAGE_RATING,
					MI.NUMBER_VOTES
			FROM	(	SELECT	T.TITLE_CONSTANT,
								T.PRIMARY_TITLE,
								T.START_YEAR,
								T.RUNTIME_MINUTES,
								T.GENRES,
								R.AVERAGE_RATING,
								R.NUMBER_VOTES
						FROM	TITLES T
						INNER JOIN
								RATINGS R
						ON		T.TITLE_CONSTANT = R.TITLE_CONSTANT
						AND		T.IS_ADULT = 0
						AND		T.TITLE_TYPE IN ('movie','short')
						AND		T.START_YEAR >= 1927
						AND		R.NUMBER_VOTES > 1000
					) MI
			LEFT JOIN
					OSCARS O
			ON		LOWER(REGEXP_REPLACE(MI.PRIMARY_TITLE,'[[:punct:][:space:]]', '','g')) = LOWER(REGEXP_REPLACE(O.FILM,'[[:punct:][:space:]]', '','g'))
			AND		MI.START_YEAR = O.YEAR_FILM
			ORDER BY MI.TITLE_CONSTANT
	) MIO
INNER JOIN
	(	SELECT	TITLE_CONSTANT,
				MAX(PRIOR_DIRECTOR_WIN) AS PRIOR_DIRECTOR_WIN,
				MAX(PRIOR_ACTOR_WIN) AS PRIOR_ACTOR_WIN,
				MAX(PRIOR_WRITER_WIN) AS PRIOR_WRITER_WIN,
				MAX(PRIOR_OTHER_WIN) AS PRIOR_OTHER_WIN
		FROM (
		SELECT	DISTINCT
				T.TITLE_CONSTANT,
				CASE
					WHEN	CATEGORY = 'director'
						AND	YEAR_FIRST_WIN IS NOT NULL
						AND	YEAR_FIRST_WIN < T.START_YEAR
					THEN
						1
					ELSE
						0
				END AS PRIOR_DIRECTOR_WIN,
				CASE
					WHEN	CATEGORY IN ('actor','actress')
						AND	YEAR_FIRST_WIN IS NOT NULL
						AND	YEAR_FIRST_WIN < T.START_YEAR
					THEN
						1
					ELSE
						0
				END AS PRIOR_ACTOR_WIN,
				CASE
					WHEN	CATEGORY = 'writer'
						AND	YEAR_FIRST_WIN IS NOT NULL
						AND	YEAR_FIRST_WIN < T.START_YEAR
					THEN
						1
					ELSE
						0
				END AS PRIOR_WRITER_WIN,
				CASE
					WHEN	CATEGORY NOT IN ('writer','actor','actress','director')
						AND	YEAR_FIRST_WIN IS NOT NULL
						AND	YEAR_FIRST_WIN < T.START_YEAR
					THEN
						1
					ELSE
						0
				END AS PRIOR_OTHER_WIN
		FROM	TITLES T
		INNER JOIN
				RATINGS R
		ON		T.TITLE_CONSTANT = R.TITLE_CONSTANT
		AND		T.IS_ADULT = 0
		AND		T.TITLE_TYPE IN ('movie','short')
		AND		T.START_YEAR >= 1927
		AND		R.NUMBER_VOTES > 1000
		INNER JOIN
				PRINCIPALS P
		ON		T.TITLE_CONSTANT = P.TITLE_CONSTANT
		INNER JOIN
				NAMES_FIRST_OSCAR NFO
		ON		P.NAME_CONSTANT = NFO.NAME_CONSTANT) A
		GROUP BY TITLE_CONSTANT
	) MPI
ON	MIO.TITLE_CONSTANT = MPI.TITLE_CONSTANT;

```

It is big, and gnarly. But it is mostly straight forward. Most of the tables are directly from the datasets that I downloaded. One exception is table NAMES_FIRST_OSCAR which is a scaled down version of the NAMES table to indicate when a particular crew person won their first Oscar (if they won one).

# What Do I Need to Learn
So much! I think? Because I was running into issues with my data right off the bat (and totally second guessing my project choice), I decided to fallback to what I know best, and that is databases. So instead of importing all of this data via R and slicing and dicing in R and building dataframes that way, I created a PostgreSQL database and imported the data into the database. This allowed me to utilize the SQL to build a targeted dataset.

Once I had the data cleaned and in a more usable manner, I imported it into R as seen in the above bullet point. While I'm sure this could have all been done in R, I was struggling and wanted something a little more familiar. But to answer the question, I need to be more comfortable with filtering, merging, and manipulating data frames in R.

I also need to understand how to document, or narrate, what I'm doing to the data. Every time I created a table, or did a join, or added a where clause there was a little voice in my head asking me, "Are you allowed to do that? Will that ruin the whole project? Is that making your data biased?" I tried to make comments and notes where I could, but in my rush to get the assignment completed, those notes did not seem nearly verbose enough. 
